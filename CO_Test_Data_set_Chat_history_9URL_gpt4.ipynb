{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2588af5e",
   "metadata": {},
   "source": [
    "### Ragas is a framework that helps you evaluate your Retrieval Augmented Generation (RAG) pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2208c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai==0.28.1\n",
    "#!pip install openai --upgrade\n",
    "#!pip install ragas\n",
    "#!pip install unstructured\n",
    "#!pip install langchain[all]\n",
    "#!pip install --upgrade langchain\n",
    "\n",
    "#!pip install playwright\n",
    "#!pip install -U selenium unstructured\n",
    "#!pip install --upgrade langchain langchain-community langchainhub langchain-openai langchain-chroma bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d63c1067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydantic==2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20e13d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "#import openai\n",
    "#from langchain.chat_models import ChatOpenAI, ChatGooglePalm\n",
    "from utils import OPENAI_API_KEY\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY \n",
    "#os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "#openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075332bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import SeleniumURLLoader, TextLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8841182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-0125-preview\", temperature=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89a48695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_questioins(path):\n",
    "    loader = TextLoader(path)\n",
    "    docs = loader.load()\n",
    "    texts = docs[0].page_content.split('\\n')\n",
    "    questions = []\n",
    "    for q in  texts:\n",
    "        if \"?\" in q:\n",
    "            questions.append(q)\n",
    "    return questions\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def load_url_documets(list_urls):\n",
    "    \n",
    "    # Load, chunk and index the contents of the blog.\n",
    "    loader_url =SeleniumURLLoader( list_urls)\n",
    "    docs = loader_url.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    \n",
    "    # Retrieve and generate using the relevant snippets of the blog.\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())   \n",
    "    retriever = vectorstore.as_retriever()\n",
    "    return retriever, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd7e9e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dict = {}\n",
    "\n",
    "url_list = [\"https://www.nature.com/articles/s41524-023-01062-z\",\n",
    "            \"https://www.nature.com/articles/s41699-023-00369-1\",\n",
    "            \"https://github.com/HSE-LAMBDA/ai4material_design/tree/main/docs/CONSTRUCTOR-MOCK.md\"\n",
    "            \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/CONSTRUCTOR.md\",\n",
    "            \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/DATA.md\",\n",
    "            \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/ENVIRONMENT.md\",\n",
    "            \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/GENERATING-CONSTRUCTOR.md\",\n",
    "            \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/GENERATING-MOCK.md\",\n",
    "            \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/PILOT.md\",\n",
    "            \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/SPARSE-PAPER.md\"\n",
    "          #  \"https://www.nature.com/articles/s41377-024-01407-3\",\n",
    "          #  \"https://www.nature.com/articles/s41565-023-01407-1\",\n",
    "          #  \"https://www.nature.com/articles/s41699-023-00369-1\",\n",
    "           ]\n",
    "                               \n",
    "retriever, documents = load_url_documets(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa7b78a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f610c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Contextualize question ###\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "### Answer question ###\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Use three sentences maximum and keep the answer concise.\\\n",
    "\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "790ea00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Statefully manage chat history ###\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61c23367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "ques = get_questioins(\"data/data_rag/Sparse representation - questions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6c541b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dict = {}\n",
    "\n",
    "for q in ques:\n",
    "    answer = conversational_rag_chain.invoke(\n",
    "              {\"input\": q},\n",
    "               config={\"configurable\": {\"session_id\": \"abc123\"}\n",
    "              },  # constructs a key \"abc123\" in `store`.\n",
    "             )[\"answer\"]\n",
    "    qa_dict[q] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "296e4e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Which materials are in the dataset?\n",
      "\n",
      "The materials in the dataset include MoS2, WSe2, hBN, GaSe, InSe, and black phosphorous.\n",
      "**********************************\n",
      "\n",
      "* How many structures are there in the dataset?\n",
      "\n",
      "The dataset contains structures with 5933 defect configurations for MoS2 and another 5933 configurations for WSe2, making a total of 11,866 defect configurations for these two materials. Additional structures for hBN, GaSe, InSe, and black phosphorus are included, but the exact numbers for these materials are not specified.\n",
      "**********************************\n",
      "\n",
      "* How to obtain the dataset?\n",
      "\n",
      "The dataset, including DFT-computed properties, relaxed atomic structures, density of states (DOS), and band structures at the DFT PBE levels, is available for further studies and machine learning training, but the specific method or platform for obtaining the dataset is not mentioned in the provided context.\n",
      "**********************************\n",
      "\n",
      "* What is the dataset license?\n",
      "\n",
      "The provided context does not specify the license under which the dataset is distributed.\n",
      "**********************************\n",
      "\n",
      "* What is the data format?\n",
      "\n",
      "The data format of the dataset is not specified in the provided context.\n",
      "**********************************\n",
      "\n",
      "* How to read the dataset?\n",
      "\n",
      "The provided context does not include instructions on how to read the dataset.\n",
      "**********************************\n",
      "\n",
      "* How to browse the dataset?\n",
      "\n",
      "The provided context does not offer information on how to browse the dataset.\n",
      "**********************************\n",
      "\n",
      "* Can I work with the dataset without Python?\n",
      "\n",
      "The provided context does not specify whether you can work with the dataset without using Python.\n",
      "**********************************\n",
      "\n",
      "* How to obtain the raw VASP files?\n",
      "\n",
      "To obtain the raw VASP files, follow these steps:\n",
      "\n",
      "1. Clone the repository where the dataset is hosted.\n",
      "2. Ensure that DVC with S3 support is installed on your system by running `pip install dvc[s3]`.\n",
      "3. Download the VASP output by executing the command: `dvc pull -R datasets/raw_vasp/high_density_defects datasets/raw_vasp/dichalcogenides8x8_vasp_nus_202110`.\n",
      "\n",
      "Some of the data are packed into tar.gz files due to their large size (~300Gb), and you might need to use ratarmount to access them.\n",
      "**********************************\n",
      "\n",
      "* What were the settings used for the DFT computations?\n",
      "\n",
      "The DFT computations were performed using the Vienna Ab initio Simulation Package (VASP) with the projector augmented wave (PAW) method. The exchange-correlation functional was treated within the generalized gradient approximation (GGA) using the Perdew-Burke-Ernzerhof (PBE) functional. The kinetic energy cutoff for the plane-wave basis set was set to 520 eV. For the Brillouin zone integration, a Gamma-centered k-point mesh was used, with the density equivalent to 24x24x1 for a unit cell of MoS2. The convergence criteria for the electronic self-consistent loop was set to 10^-6 eV, and the force convergence criterion for ionic relaxations was set to 0.01 eV/Å.\n",
      "**********************************\n",
      "\n",
      "* How well the DFT calculations correspond to experiment?\n",
      "\n",
      "The provided context does not include specific details on how well the DFT calculations correspond to experimental results.\n",
      "**********************************\n",
      "\n",
      "* How to cite the dataset?\n",
      "\n",
      "The provided context does not include specific information on how to cite the dataset.\n",
      "**********************************\n",
      "\n",
      "* What was the procedure for SRGNN quality evaluation?\n",
      "\n",
      "The provided context does not detail the procedure for SRGNN (Sparse Representation Graph Neural Network) quality evaluation.\n",
      "**********************************\n",
      "\n",
      "* How is SRGNN different from the baselines?\n",
      "\n",
      "SRGNN (Sparse Representation Graph Neural Network) differs from the baselines in several key aspects:\n",
      "\n",
      "1. **Sparse Representation**: It utilizes a sparse representation of the data, which significantly reduces the computational resources required for training, such as memory usage and GPU operations.\n",
      "2. **Efficiency and Performance**: The sparse representation allows SRGNN to achieve lower prediction errors (3.7 times lower than the nearest contender) and to be computationally more efficient, requiring at least 4x less memory and 8x less GPU operations compared to full representations.\n",
      "3. **Compatibility and Flexibility**: SRGNN's representation is compatible with any machine learning algorithm that is based on point clouds, offering a versatile approach to exploring crystal configurations.\n",
      "\n",
      "These differences highlight SRGNN's advancements in efficiency, performance, and flexibility over traditional baselines.\n",
      "**********************************\n",
      "\n",
      "* What are the limitations of SRGNN?\n",
      "\n",
      "The provided context does not explicitly mention the limitations of SRGNN (Sparse Representation Graph Neural Network).\n",
      "**********************************\n",
      "\n",
      "* What is the core idea of SRGNN?\n",
      "\n",
      "The core idea of SRGNN (Sparse Representation Graph Neural Network) is to efficiently and effectively model crystal structures using a sparse representation within a graph neural network framework. This approach significantly reduces the computational resources needed for training, such as memory and GPU operations, by focusing on the essential elements of the structure, like point defects, and their interactions. It aims to provide a practical and sound method for exploring a vast domain of possible crystal configurations with high accuracy and lower computational cost.\n",
      "**********************************\n",
      "\n",
      "* How to run the code?\n",
      "\n",
      "To run the code, follow these general steps based on the provided context:\n",
      "\n",
      "1. **Install Poetry**: First, ensure Poetry is installed on your system. Poetry is a tool for dependency management and packaging in Python.\n",
      "\n",
      "2. **Setup the Environment**:\n",
      "   - If you prefer not to use a virtual environment and want to use system-wide installations (e.g., system torch), configure Poetry with the command `poetry config virtualenvs.create false --local`.\n",
      "   - If you want to use a virtual environment, activate it by running `poetry shell`.\n",
      "\n",
      "3. **Install Dependencies**: Install the necessary dependencies for the project. The exact command isn't provided, but typically, after activating the environment or setting up Poetry, you would run `poetry install` to install the dependencies specified in the `pyproject.toml` file.\n",
      "\n",
      "4. **Data and Pre-trained Models**: The context mentions that all input, intermediate, and output data, as well as pre-trained models, are available in DVC. You would use DVC commands to pull the necessary data and models. For example, `dvc pull datasets/checkpoints/...` to retrieve specific datasets or model checkpoints.\n",
      "\n",
      "5. **Running Specific Code**: The exact commands to run the project's code are not provided. Typically, you would navigate to the directory containing the project's scripts and run Python scripts directly (e.g., `python script_name.py`) or follow specific instructions provided in the project's documentation for running applications or notebooks.\n",
      "\n",
      "Remember, these steps are generalized based on the context provided and the actual commands or steps may vary depending on the specific requirements of the project and its documentation.\n",
      "**********************************\n",
      "\n",
      "* Which frameworks were used for SRGNN implementation?\n",
      "\n",
      "The provided context does not specify which frameworks were used for the implementation of SRGNN (Sparse Representation Graph Neural Network).\n",
      "**********************************\n",
      "\n",
      "* Can SRGNN be developed on a CPU, not a GPU?\n",
      "\n",
      "The provided context does not directly address whether SRGNN (Sparse Representation Graph Neural Network) can be developed or run on a CPU instead of a GPU. However, given that SRGNN is designed to be computationally efficient, requiring at least 4x less memory and 8x less GPU operations compared to full representations, it suggests that the model could potentially be adapted for CPU usage, especially for tasks that do not demand extensive computational resources.\n",
      "**********************************\n",
      "\n",
      "* What is the code license?\n",
      "\n",
      "The provided context does not specify the license under which the code is distributed.\n",
      "**********************************\n",
      "\n",
      "* How to cite the code?\n",
      "\n",
      "The provided context does not include specific information on how to cite the code.\n",
      "**********************************\n",
      "\n",
      "* Which materials has the SRGNN been trained on?\n",
      "\n",
      "The provided context does not specify the exact materials on which the SRGNN (Sparse Representation Graph Neural Network) has been trained.\n",
      "**********************************\n",
      "\n",
      "* Which materials can the SRGNN be trained on?\n",
      "\n",
      "Based on the provided context, SRGNN (Sparse Representation Graph Neural Network) is designed to be compatible with any machine learning algorithm based on point clouds, suggesting it can be trained on a wide range of materials. Specifically, it has been mentioned in relation to exploring a vast domain of possible crystal configurations confidently, indicating its applicability to various crystalline materials. However, the exact range of materials it can be trained on is not detailed in the provided context.\n",
      "**********************************\n",
      "\n",
      "* Which defect types can the SRGNN be trained on?\n",
      "\n",
      "The provided context does not specify the exact types of defects that SRGNN (Sparse Representation Graph Neural Network) can be trained on.\n",
      "**********************************\n",
      "\n",
      "* How many structures are needed for SRGNN training?\n",
      "\n",
      "The provided context does not specify the minimum number of structures required for training the SRGNN (Sparse Representation Graph Neural Network).\n",
      "**********************************\n",
      "\n",
      "* Can SRGNN handle 3D materials?\n",
      "\n",
      "The provided context does not explicitly state whether SRGNN (Sparse Representation Graph Neural Network) can handle 3D materials. However, given that it is designed to work with any machine learning algorithm based on point clouds and is used for exploring crystal configurations, it implies a capability to model structures that could be extended to 3D materials.\n",
      "**********************************\n",
      "\n",
      "* How much computational resources does SRGNN require for training?\n",
      "\n",
      "Training a Sparse Representation Graph Neural Network (SRGNN) requires significantly less computational resources compared to full representations. Specifically, it takes at least 4x less memory and 8x less GPU operations. This efficiency allows for more economical use of computational resources, such as fitting 4 simultaneous runs on a single GPU with 16 GiB RAM without losing speed, a feat not possible with Graph Neural Networks (GNNs) running on full representations.\n",
      "**********************************\n",
      "\n",
      "* What is the inference speed of a SRGNN?\n",
      "\n",
      "The provided context does not specify the inference speed of a Sparse Representation Graph Neural Network (SRGNN).\n",
      "**********************************\n",
      "\n",
      "* Which properties can be predicted using SRGNN?\n",
      "\n",
      "The provided context does not specify which properties can be predicted using SRGNN (Sparse Representation Graph Neural Network).\n",
      "**********************************\n",
      "\n",
      "* What was the quality of SRGNN for each property and material?\n",
      "\n",
      "The provided context does not detail the quality of SRGNN (Sparse Representation Graph Neural Network) predictions for each property and material.\n",
      "**********************************\n",
      "\n",
      "* Can pre-trained SRGNN be used out-of-the-box?\n",
      "\n",
      "The provided context does not explicitly state whether a pre-trained SRGNN (Sparse Representation Graph Neural Network) can be used out-of-the-box. However, the mention of pre-trained models being available suggests there may be potential for such models to be applied directly to compatible tasks or datasets without the need for initial training from the user.\n",
      "**********************************\n",
      "\n",
      "* How well do SRGNN results correspond to experiment?\n",
      "\n",
      "The provided context does not include information on how well SRGNN (Sparse Representation Graph Neural Network) results correspond to experimental data.\n",
      "**********************************\n",
      "\n",
      "* Can I use SRGNN in place of DFT?\n",
      "\n",
      "The provided context does not directly address whether SRGNN (Sparse Representation Graph Neural Network) can be used in place of Density Functional Theory (DFT) computations. SRGNN is designed for efficient exploration of crystal configurations and prediction of their properties, potentially offering a complementary tool to DFT by reducing computational demands for certain tasks. However, whether it can serve as a direct replacement for DFT would depend on the specific requirements of the application, including the accuracy needed and the types of properties being predicted.\n",
      "**********************************\n",
      "\n",
      "* How can I use SRGNN to find materials for solar panels/transistors/photodetectors/single photon emitters/quantum computers?\n",
      "\n",
      "The provided context does not include specific instructions on how to use SRGNN (Sparse Representation Graph Neural Network) to find materials for solar panels, transistors, photodetectors, single photon emitters, or quantum computers. However, generally, SRGNN could be applied to these areas by training it on datasets of materials known to be effective in these applications, using it to predict properties relevant to each application (e.g., bandgap for solar panels, electron mobility for transistors), and then screening for materials that meet desired criteria. The effectiveness of SRGNN in these specific applications would depend on the quality and relevance of the training data, as well as the accuracy of SRGNN's predictions for the properties of interest.\n",
      "**********************************\n",
      "\n",
      "* Is SRGNN patented?\n",
      "\n",
      "The provided context does not specify whether SRGNN (Sparse Representation Graph Neural Network) is patented.\n",
      "**********************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l_answer, l_question = [], []\n",
    "\n",
    "for k,v in qa_dict.items():\n",
    "    print(k)\n",
    "    print()\n",
    "    print(v)\n",
    "    print(\"**********************************\")\n",
    "    print()\n",
    "    l_answer.append(v)\n",
    "    l_question.append(k)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8da5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data_rag/qa_dict_9docs&chatHistory_gpt-4-0125-preview.json', 'w') as fp:\n",
    "    json.dump(qa_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f9a58e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: * Which materials are in the dataset?\n",
      "AI: The materials in the dataset include MoS2, WSe2, hBN, GaSe, InSe, and black phosphorous.\n",
      "\n",
      "Human: * How many structures are there in the dataset?\n",
      "AI: The dataset contains structures with 5933 defect configurations for MoS2 and another 5933 configurations for WSe2, making a total of 11,866 defect configurations for these two materials. Additional structures for hBN, GaSe, InSe, and black phosphorus are included, but the exact numbers for these materials are not specified.\n",
      "\n",
      "Human: * How to obtain the dataset?\n",
      "AI: The dataset, including DFT-computed properties, relaxed atomic structures, density of states (DOS), and band structures at the DFT PBE levels, is available for further studies and machine learning training, but the specific method or platform for obtaining the dataset is not mentioned in the provided context.\n",
      "\n",
      "Human: * What is the dataset license?\n",
      "AI: The provided context does not specify the license under which the dataset is distributed.\n",
      "\n",
      "Human: * What is the data format?\n",
      "AI: The data format of the dataset is not specified in the provided context.\n",
      "\n",
      "Human: * How to read the dataset?\n",
      "AI: The provided context does not include instructions on how to read the dataset.\n",
      "\n",
      "Human: * How to browse the dataset?\n",
      "AI: The provided context does not offer information on how to browse the dataset.\n",
      "\n",
      "Human: * Can I work with the dataset without Python?\n",
      "AI: The provided context does not specify whether you can work with the dataset without using Python.\n",
      "\n",
      "Human: * How to obtain the raw VASP files?\n",
      "AI: To obtain the raw VASP files, follow these steps:\n",
      "\n",
      "1. Clone the repository where the dataset is hosted.\n",
      "2. Ensure that DVC with S3 support is installed on your system by running `pip install dvc[s3]`.\n",
      "3. Download the VASP output by executing the command: `dvc pull -R datasets/raw_vasp/high_density_defects datasets/raw_vasp/dichalcogenides8x8_vasp_nus_202110`.\n",
      "\n",
      "Some of the data are packed into tar.gz files due to their large size (~300Gb), and you might need to use ratarmount to access them.\n",
      "\n",
      "Human: * What were the settings used for the DFT computations?\n",
      "AI: The DFT computations were performed using the Vienna Ab initio Simulation Package (VASP) with the projector augmented wave (PAW) method. The exchange-correlation functional was treated within the generalized gradient approximation (GGA) using the Perdew-Burke-Ernzerhof (PBE) functional. The kinetic energy cutoff for the plane-wave basis set was set to 520 eV. For the Brillouin zone integration, a Gamma-centered k-point mesh was used, with the density equivalent to 24x24x1 for a unit cell of MoS2. The convergence criteria for the electronic self-consistent loop was set to 10^-6 eV, and the force convergence criterion for ionic relaxations was set to 0.01 eV/Å.\n",
      "\n",
      "Human: * How well the DFT calculations correspond to experiment?\n",
      "AI: The provided context does not include specific details on how well the DFT calculations correspond to experimental results.\n",
      "\n",
      "Human: * How to cite the dataset?\n",
      "AI: The provided context does not include specific information on how to cite the dataset.\n",
      "\n",
      "Human: * What was the procedure for SRGNN quality evaluation?\n",
      "AI: The provided context does not detail the procedure for SRGNN (Sparse Representation Graph Neural Network) quality evaluation.\n",
      "\n",
      "Human: * How is SRGNN different from the baselines?\n",
      "AI: SRGNN (Sparse Representation Graph Neural Network) differs from the baselines in several key aspects:\n",
      "\n",
      "1. **Sparse Representation**: It utilizes a sparse representation of the data, which significantly reduces the computational resources required for training, such as memory usage and GPU operations.\n",
      "2. **Efficiency and Performance**: The sparse representation allows SRGNN to achieve lower prediction errors (3.7 times lower than the nearest contender) and to be computationally more efficient, requiring at least 4x less memory and 8x less GPU operations compared to full representations.\n",
      "3. **Compatibility and Flexibility**: SRGNN's representation is compatible with any machine learning algorithm that is based on point clouds, offering a versatile approach to exploring crystal configurations.\n",
      "\n",
      "These differences highlight SRGNN's advancements in efficiency, performance, and flexibility over traditional baselines.\n",
      "\n",
      "Human: * What are the limitations of SRGNN?\n",
      "AI: The provided context does not explicitly mention the limitations of SRGNN (Sparse Representation Graph Neural Network).\n",
      "\n",
      "Human: * What is the core idea of SRGNN?\n",
      "AI: The core idea of SRGNN (Sparse Representation Graph Neural Network) is to efficiently and effectively model crystal structures using a sparse representation within a graph neural network framework. This approach significantly reduces the computational resources needed for training, such as memory and GPU operations, by focusing on the essential elements of the structure, like point defects, and their interactions. It aims to provide a practical and sound method for exploring a vast domain of possible crystal configurations with high accuracy and lower computational cost.\n",
      "\n",
      "Human: * How to run the code?\n",
      "AI: To run the code, follow these general steps based on the provided context:\n",
      "\n",
      "1. **Install Poetry**: First, ensure Poetry is installed on your system. Poetry is a tool for dependency management and packaging in Python.\n",
      "\n",
      "2. **Setup the Environment**:\n",
      "   - If you prefer not to use a virtual environment and want to use system-wide installations (e.g., system torch), configure Poetry with the command `poetry config virtualenvs.create false --local`.\n",
      "   - If you want to use a virtual environment, activate it by running `poetry shell`.\n",
      "\n",
      "3. **Install Dependencies**: Install the necessary dependencies for the project. The exact command isn't provided, but typically, after activating the environment or setting up Poetry, you would run `poetry install` to install the dependencies specified in the `pyproject.toml` file.\n",
      "\n",
      "4. **Data and Pre-trained Models**: The context mentions that all input, intermediate, and output data, as well as pre-trained models, are available in DVC. You would use DVC commands to pull the necessary data and models. For example, `dvc pull datasets/checkpoints/...` to retrieve specific datasets or model checkpoints.\n",
      "\n",
      "5. **Running Specific Code**: The exact commands to run the project's code are not provided. Typically, you would navigate to the directory containing the project's scripts and run Python scripts directly (e.g., `python script_name.py`) or follow specific instructions provided in the project's documentation for running applications or notebooks.\n",
      "\n",
      "Remember, these steps are generalized based on the context provided and the actual commands or steps may vary depending on the specific requirements of the project and its documentation.\n",
      "\n",
      "Human: * Which frameworks were used for SRGNN implementation?\n",
      "AI: The provided context does not specify which frameworks were used for the implementation of SRGNN (Sparse Representation Graph Neural Network).\n",
      "\n",
      "Human: * Can SRGNN be developed on a CPU, not a GPU?\n",
      "AI: The provided context does not directly address whether SRGNN (Sparse Representation Graph Neural Network) can be developed or run on a CPU instead of a GPU. However, given that SRGNN is designed to be computationally efficient, requiring at least 4x less memory and 8x less GPU operations compared to full representations, it suggests that the model could potentially be adapted for CPU usage, especially for tasks that do not demand extensive computational resources.\n",
      "\n",
      "Human: * What is the code license?\n",
      "AI: The provided context does not specify the license under which the code is distributed.\n",
      "\n",
      "Human: * How to cite the code?\n",
      "AI: The provided context does not include specific information on how to cite the code.\n",
      "\n",
      "Human: * Which materials has the SRGNN been trained on?\n",
      "AI: The provided context does not specify the exact materials on which the SRGNN (Sparse Representation Graph Neural Network) has been trained.\n",
      "\n",
      "Human: * Which materials can the SRGNN be trained on?\n",
      "AI: Based on the provided context, SRGNN (Sparse Representation Graph Neural Network) is designed to be compatible with any machine learning algorithm based on point clouds, suggesting it can be trained on a wide range of materials. Specifically, it has been mentioned in relation to exploring a vast domain of possible crystal configurations confidently, indicating its applicability to various crystalline materials. However, the exact range of materials it can be trained on is not detailed in the provided context.\n",
      "\n",
      "Human: * Which defect types can the SRGNN be trained on?\n",
      "AI: The provided context does not specify the exact types of defects that SRGNN (Sparse Representation Graph Neural Network) can be trained on.\n",
      "\n",
      "Human: * How many structures are needed for SRGNN training?\n",
      "AI: The provided context does not specify the minimum number of structures required for training the SRGNN (Sparse Representation Graph Neural Network).\n",
      "\n",
      "Human: * Can SRGNN handle 3D materials?\n",
      "AI: The provided context does not explicitly state whether SRGNN (Sparse Representation Graph Neural Network) can handle 3D materials. However, given that it is designed to work with any machine learning algorithm based on point clouds and is used for exploring crystal configurations, it implies a capability to model structures that could be extended to 3D materials.\n",
      "\n",
      "Human: * How much computational resources does SRGNN require for training?\n",
      "AI: Training a Sparse Representation Graph Neural Network (SRGNN) requires significantly less computational resources compared to full representations. Specifically, it takes at least 4x less memory and 8x less GPU operations. This efficiency allows for more economical use of computational resources, such as fitting 4 simultaneous runs on a single GPU with 16 GiB RAM without losing speed, a feat not possible with Graph Neural Networks (GNNs) running on full representations.\n",
      "\n",
      "Human: * What is the inference speed of a SRGNN?\n",
      "AI: The provided context does not specify the inference speed of a Sparse Representation Graph Neural Network (SRGNN).\n",
      "\n",
      "Human: * Which properties can be predicted using SRGNN?\n",
      "AI: The provided context does not specify which properties can be predicted using SRGNN (Sparse Representation Graph Neural Network).\n",
      "\n",
      "Human: * What was the quality of SRGNN for each property and material?\n",
      "AI: The provided context does not detail the quality of SRGNN (Sparse Representation Graph Neural Network) predictions for each property and material.\n",
      "\n",
      "Human: * Can pre-trained SRGNN be used out-of-the-box?\n",
      "AI: The provided context does not explicitly state whether a pre-trained SRGNN (Sparse Representation Graph Neural Network) can be used out-of-the-box. However, the mention of pre-trained models being available suggests there may be potential for such models to be applied directly to compatible tasks or datasets without the need for initial training from the user.\n",
      "\n",
      "Human: * How well do SRGNN results correspond to experiment?\n",
      "AI: The provided context does not include information on how well SRGNN (Sparse Representation Graph Neural Network) results correspond to experimental data.\n",
      "\n",
      "Human: * Can I use SRGNN in place of DFT?\n",
      "AI: The provided context does not directly address whether SRGNN (Sparse Representation Graph Neural Network) can be used in place of Density Functional Theory (DFT) computations. SRGNN is designed for efficient exploration of crystal configurations and prediction of their properties, potentially offering a complementary tool to DFT by reducing computational demands for certain tasks. However, whether it can serve as a direct replacement for DFT would depend on the specific requirements of the application, including the accuracy needed and the types of properties being predicted.\n",
      "\n",
      "Human: * How can I use SRGNN to find materials for solar panels/transistors/photodetectors/single photon emitters/quantum computers?\n",
      "AI: The provided context does not include specific instructions on how to use SRGNN (Sparse Representation Graph Neural Network) to find materials for solar panels, transistors, photodetectors, single photon emitters, or quantum computers. However, generally, SRGNN could be applied to these areas by training it on datasets of materials known to be effective in these applications, using it to predict properties relevant to each application (e.g., bandgap for solar panels, electron mobility for transistors), and then screening for materials that meet desired criteria. The effectiveness of SRGNN in these specific applications would depend on the quality and relevance of the training data, as well as the accuracy of SRGNN's predictions for the properties of interest.\n",
      "\n",
      "Human: * Is SRGNN patented?\n",
      "AI: The provided context does not specify whether SRGNN (Sparse Representation Graph Neural Network) is patented.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in conversational_rag_chain.get_session_history(\"abc123\").messages:\n",
    "    \n",
    "    if m.type == 'human':\n",
    "        print('Human: ' + m.content)\n",
    "    elif  m.type == 'ai':\n",
    "        print('AI: ' + m.content)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86e3755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "l_answer, l_question = [], []\n",
    "\n",
    "for m in conversational_rag_chain.get_session_history(\"abc123\").messages:\n",
    "    \n",
    "    if m.type == 'human':\n",
    "        l_question.append(m.content)\n",
    "    elif  m.type == 'ai':\n",
    "        l_answer.append(m.content)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['question'] = l_question\n",
    "#df['Content'] = doc_url[0].metadata['description']\n",
    "df['answer'] = l_answer\n",
    "df['number of documets'] = len(documents)\n",
    "#for i in range(len(documents)):\n",
    "    #df[f'Content_{i}'] = documents[i].metadata['description']\n",
    "    #df[f'Titles_{i}'] = documents[i].metadata['title']\n",
    "    #df[f'Urls_{i}'] = documents[i].metadata['source']\n",
    "\n",
    "df.to_csv(\"data/data_rag/9docs&chatHistory_gpt-4-0125-preview.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390374f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
