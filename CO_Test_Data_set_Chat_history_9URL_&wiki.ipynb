{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2588af5e",
   "metadata": {},
   "source": [
    "### Ragas is a framework that helps you evaluate your Retrieval Augmented Generation (RAG) pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2208c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai==0.28.1\n",
    "#!pip install openai --upgrade\n",
    "#!pip install ragas\n",
    "#!pip install unstructured\n",
    "#!pip install langchain[all]\n",
    "#!pip install --upgrade langchain\n",
    "\n",
    "#!pip install playwright\n",
    "#!pip install -U selenium unstructured\n",
    "#!pip install --upgrade langchain langchain-community langchainhub langchain-openai langchain-chroma bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63c1067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /home/oleg/miniconda3/envs/llm/lib/python3.10/site-packages (from wikipedia) (4.12.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /home/oleg/miniconda3/envs/llm/lib/python3.10/site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/oleg/miniconda3/envs/llm/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/oleg/miniconda3/envs/llm/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/oleg/miniconda3/envs/llm/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/oleg/miniconda3/envs/llm/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/oleg/miniconda3/envs/llm/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.4.1)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=a8bf0301e1f28e7ecbbf9c999ba615bf5f506cd408f9aaefbcb74426293776d8\n",
      "  Stored in directory: /home/oleg/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install pydantic==2.5\n",
    "#!pip install langchain-experimental==0.0.57\n",
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20e13d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "#import openai\n",
    "#from langchain.chat_models import ChatOpenAI, ChatGooglePalm\n",
    "from utils import OPENAI_API_KEY\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY \n",
    "#os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "#openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "075332bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import SeleniumURLLoader, TextLoader\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.document_loaders.merge import MergedDataLoader\n",
    "\n",
    "\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8841182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4-0125-preview\", temperature=0.)\n",
    "emb_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "89a48695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_questioins(path):\n",
    "    loader = TextLoader(path)\n",
    "    docs = loader.load()\n",
    "    texts = docs[0].page_content.split('\\n')\n",
    "    questions = []\n",
    "    for q in  texts:\n",
    "        if \"?\" in q:\n",
    "            questions.append(q)\n",
    "    return questions\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def load_url_documets(list_urls, wiki=None):\n",
    "    \n",
    "    # Load, chunk and index the contents of the blog.\n",
    "    \n",
    "    loader_url =SeleniumURLLoader( list_urls) # URL Loader\n",
    "    # Wikipedia Loader\n",
    "    if  wiki is not None:\n",
    "        if type(wiki) == str:\n",
    "            loader_wiki = WikipediaLoader(query=query)\n",
    "            loader = MergedDataLoader([loader_url, loader_wiki])\n",
    "        elif type(wiki) == list:\n",
    "            loader_wiki = []\n",
    "            for q in wiki: \n",
    "                loader_wiki.append(WikipediaLoader(query=q))\n",
    "            loader = MergedDataLoader([loader_url] + loader_wiki) # Merged Loader\n",
    "    else:\n",
    "        loader = loader_url\n",
    "    \n",
    "    docs = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "    #text_splitter = SemanticChunker(emb_model) \n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    \n",
    "    # Retrieve and generate using the relevant snippets of the blog.\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())   \n",
    "    retriever = vectorstore.as_retriever()\n",
    "    return retriever, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd7e9e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dict = {}\n",
    "\n",
    "url_list = [\"https://www.nature.com/articles/s41524-023-01062-z\",\n",
    "            \"https://www.nature.com/articles/s41699-023-00369-1\",\n",
    "            \"https://github.com/HSE-LAMBDA/ai4material_design/tree/main/docs/CONSTRUCTOR-MOCK.md\"\n",
    "            \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/CONSTRUCTOR.md\",\n",
    "            \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/DATA.md\",\n",
    "            \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/ENVIRONMENT.md\",\n",
    "            \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/GENERATING-CONSTRUCTOR.md\",\n",
    "            \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/GENERATING-MOCK.md\",\n",
    "            \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/PILOT.md\",\n",
    "            \"https://github.com/HSE-LAMBDA/ai4material_design/blob/main/docs/SPARSE-PAPER.md\"\n",
    "          #  \"https://www.nature.com/articles/s41377-024-01407-3\",\n",
    "          #  \"https://www.nature.com/articles/s41565-023-01407-1\",\n",
    "          #  \"https://www.nature.com/articles/s41699-023-00369-1\",\n",
    "           ]\n",
    "                               \n",
    "retriever, documents = load_url_documets(url_list, [\"Density Functional Theory\",  \"Graph NN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa7b78a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f610c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Contextualize question ###\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "### Answer question ###\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Use three sentences maximum and keep the answer concise.\\\n",
    "\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "790ea00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Statefully manage chat history ###\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "61c23367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "ques = get_questioins(\"data/data_rag/Sparse representation - questions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d6c541b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dict = {}\n",
    "\n",
    "for q in ques:\n",
    "    answer = conversational_rag_chain.invoke(\n",
    "              {\"input\": q},\n",
    "               config={\"configurable\": {\"session_id\": \"abc123\"}\n",
    "              },  # constructs a key \"abc123\" in `store`.\n",
    "             )[\"answer\"]\n",
    "    qa_dict[q] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "296e4e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Which materials are in the dataset?\n",
      "\n",
      "The dataset includes materials with and without defects, specifically focusing on TMDCs (transition metal dichalcogenides) and six represented 2D materials. It is based on high throughput DFT (Density Functional Theory) calculations.\n",
      "**********************************\n",
      "\n",
      "* How many structures are there in the dataset?\n",
      "\n",
      "The dataset contains a total of 14,866 configurations, comprising 11,866 defect configurations in TMDCs and 3,000 configurations in six represented 2D materials.\n",
      "**********************************\n",
      "\n",
      "* How to obtain the dataset?\n",
      "\n",
      "I don't have the specific details on how to obtain the dataset from the provided context. Typically, datasets like these might be accessible through academic publications, associated data repositories, or directly contacting the authors of the studies mentioned.\n",
      "**********************************\n",
      "\n",
      "* What is the dataset license?\n",
      "\n",
      "The provided context does not specify the license under which the dataset is distributed. Dataset licenses can vary, often aiming to define how the data can be used, shared, and modified.\n",
      "**********************************\n",
      "\n",
      "* What is the data format?\n",
      "\n",
      "The data is provided in two formats: processed data containing only the variables used for machine learning (ML) model evaluation, and the full raw VASP (Vienna Ab initio Simulation Package) output.\n",
      "**********************************\n",
      "\n",
      "* How to read the dataset?\n",
      "\n",
      "To read the dataset, the raw VASP output is first converted into CSV or CIF formats, then into a platform-specific pickle storage for efficient access. This process involves extracting computed energy and HOMO-LUMO gap values, saving unrelaxed structures uniformly, and preprocessing target values like formation energy per site.\n",
      "**********************************\n",
      "\n",
      "* How to browse the dataset?\n",
      "\n",
      "The provided context does not include specific instructions on browsing the dataset. Typically, browsing a dataset involves accessing its files through a data management tool or software that supports the dataset's format (CSV, CIF, pickle), which might be facilitated by scripts or commands provided by the dataset creators or using standard data analysis tools like Python's pandas library for CSV files or PyCIFRW for CIF files.\n",
      "**********************************\n",
      "\n",
      "* Can I work with the dataset without Python?\n",
      "\n",
      "Yes, you can work with the dataset without Python if the data is in formats such as CSV or CIF, which can be opened with various software tools not requiring Python. For example, CSV files can be viewed and edited in spreadsheet applications like Microsoft Excel or Google Sheets, and CIF files can be handled by specialized crystallography software. However, for advanced analyses or transformations, especially those involving the matminer features or machine learning models, Python or similar programming environments might be necessary.\n",
      "**********************************\n",
      "\n",
      "* How to obtain the raw VASP files?\n",
      "\n",
      "To obtain the raw VASP files, follow these steps:\n",
      "\n",
      "1. Clone the repository where the dataset is hosted.\n",
      "2. Ensure that DVC with S3 support is installed on your system by running `pip install dvc[s3]`.\n",
      "3. Use the command `dvc pull -R datasets/raw_vasp/high_density_defects datasets/raw_vasp/dichalcogenides8x8_vasp_nus_202110` to download the VASP output files.\n",
      "\n",
      "This process will download the necessary files from the dataset, which include the raw VASP output.\n",
      "**********************************\n",
      "\n",
      "* What were the settings used for the DFT computations?\n",
      "\n",
      "The DFT computations were performed using the Vienna Ab initio Simulation Package (VASP) with the projector augmented-wave (PAW) method. The exchange-correlation functional was treated within the generalized gradient approximation (GGA) using the Perdew-Burke-Ernzerhof (PBE) functional. The energy cutoff for the plane-wave basis set was set to 520 eV. A Monkhorst-Pack k-point mesh with a density of approximately 1000 k-points per reciprocal atom was used for Brillouin zone integration. The convergence criteria for the electronic self-consistent loop was set to 10^-6 eV, and the force convergence criterion for ionic relaxations was set to 0.01 eV/Å.\n",
      "**********************************\n",
      "\n",
      "* How well the DFT calculations correspond to experiment?\n",
      "\n",
      "The provided context does not specifically address the accuracy of the DFT calculations in comparison to experimental results. Generally, the accuracy of DFT calculations in predicting material properties can vary depending on the system under study and the specific DFT method and parameters used. While DFT is widely used for its balance of computational efficiency and predictive capability, discrepancies between DFT predictions and experimental outcomes can occur, especially for complex material behaviors or when subtle electronic effects are important.\n",
      "**********************************\n",
      "\n",
      "* How to cite the dataset?\n",
      "\n",
      "I don't have the specific citation information for the dataset from the provided context. Typically, to cite a dataset, you would include the title of the dataset, the author(s), the year of publication, the version (if applicable), and a persistent identifier such as a DOI (Digital Object Identifier). If the dataset is associated with a specific publication, citing that publication according to its recommended citation style would also be appropriate. For precise citation instructions, it's best to refer to the dataset's documentation or the publication that introduces or describes the dataset.\n",
      "**********************************\n",
      "\n",
      "* What was the procedure for SRGNN quality evaluation?\n",
      "\n",
      "The provided context does not detail the specific procedure for evaluating the quality of the SRGNN (Sub-Resolution Graph Neural Network) model. Quality evaluation of machine learning models, including graph neural networks like SRGNN, typically involves comparing the model's predictions against known outcomes in a test dataset. Metrics such as accuracy, precision, recall, F1 score, mean absolute error (MAE), and mean squared error (MSE) are commonly used for evaluation. The procedure might also include cross-validation to assess the model's generalizability and robustness across different subsets of the data.\n",
      "**********************************\n",
      "\n",
      "* How is SRGNN different from the baselines?\n",
      "\n",
      "I don't have specific details on how SRGNN (Sub-Resolution Graph Neural Network) differs from baseline models from the provided context. Generally, SRGNNs might be designed to address specific challenges or exploit particular characteristics of the data that are not adequately handled by baseline models. Differences could include the architecture of the network, the way data is processed and represented, the learning algorithm, or the specific task the model is designed for. Baseline models often represent standard approaches in the field, and an SRGNN would be expected to offer improvements in performance, efficiency, or applicability to complex or nuanced problems.\n",
      "**********************************\n",
      "\n",
      "* What are the limitations of SRGNN?\n",
      "\n",
      "The provided context does not specify the limitations of the Sub-Resolution Graph Neural Network (SRGNN). Generally, limitations of GNNs, including SRGNNs, might involve challenges in scaling to very large graphs, difficulty in capturing long-range dependencies within the graph, or limitations in the model's expressiveness due to the inherent constraints of the graph neural network architecture. Additionally, GNNs can struggle with graphs that have highly irregular structures or where the graph topology changes dynamically.\n",
      "**********************************\n",
      "\n",
      "* What is the core idea of SRGNN?\n",
      "\n",
      "I don't have specific details on the core idea of the Sub-Resolution Graph Neural Network (SRGNN) from the provided context. Generally, the core idea of a Graph Neural Network (GNN) involves leveraging the graph structure of data, where data points (nodes) and their relationships (edges) are explicitly modeled, allowing the network to learn representations not just based on individual data points but also based on their connections. An SRGNN might extend this concept to focus on capturing sub-resolution features or patterns within the graph that are not easily discernible at a higher level, potentially improving the model's ability to understand complex dependencies or structures within the data.\n",
      "**********************************\n",
      "\n",
      "* How to run the code?\n",
      "\n",
      "To run the code based on the provided context, follow these general steps:\n",
      "\n",
      "1. **Set up the environment**:\n",
      "   - Refer to `ENVIRONMENT.md` for instructions on setting up the necessary environment. This may involve installing specific software, libraries, or dependencies.\n",
      "\n",
      "2. **Install DVC with S3 support**:\n",
      "   - Ensure you have DVC installed with support for S3 storage by running `pip install dvc[s3]`. This is necessary for data version control and accessing the dataset stored in S3.\n",
      "\n",
      "3. **Clone the repository**:\n",
      "   - Clone the repository where the code and dataset are hosted to your local machine.\n",
      "\n",
      "4. **Download the dataset**:\n",
      "   - Use DVC commands to pull the dataset from the repository. If the dataset is hosted on an external platform like the Constructor Research Platform, you may need to download it directly from there.\n",
      "\n",
      "5. **Run the notebook for model inference**:\n",
      "   - Open the provided notebook that demonstrates how to use the pre-trained models for predictions. This notebook will likely guide you through loading the dataset, making predictions, and possibly evaluating the model's performance.\n",
      "\n",
      "Remember, these steps are based on common practices and the specific instructions provided in the context. Adjustments might be needed depending on the exact setup of the repository and the environment.\n",
      "**********************************\n",
      "\n",
      "* Which frameworks were used for SRGNN implementation?\n",
      "\n",
      "The provided context does not specify the frameworks used for the implementation of the Sub-Resolution Graph Neural Network (SRGNN). However, popular frameworks for implementing graph neural networks include PyTorch Geometric (PyG) for PyTorch users, TensorFlow GNN for TensorFlow users, jraph for Google JAX users, and GraphNeuralNetworks.jl or GeometricFlux.jl for those working with Julia. These frameworks offer comprehensive tools and libraries specifically designed for developing and training GNNs, including SRGNNs, if applicable.\n",
      "**********************************\n",
      "\n",
      "* Can SRGNN be developed on a CPU, not a GPU?\n",
      "\n",
      "Yes, SRGNN (Sub-Resolution Graph Neural Network) can be developed and run on a CPU. While GPUs offer faster computation for many machine learning tasks, including training graph neural networks due to their parallel processing capabilities, it is entirely possible to develop and train GNNs on CPUs. However, training on a CPU may be significantly slower, especially for large datasets or complex network architectures, and might limit the scale of experiments or the speed of iterative development.\n",
      "**********************************\n",
      "\n",
      "* What is the code license?\n",
      "\n",
      "The provided context does not specify the license under which the code is distributed. Code licenses define how software can be used, modified, and distributed. Common open-source licenses include the MIT License, GNU General Public License (GPL), Apache License 2.0, and BSD licenses. For specific code license details, it's important to check the repository's documentation or contact the authors directly.\n",
      "**********************************\n",
      "\n",
      "* How to cite the code?\n",
      "\n",
      "I don't have specific citation information for the code from the provided context. Typically, to cite code, you would include the author(s), title of the software or code repository, the year of the latest release, the version (if applicable), and a persistent identifier such as a DOI (Digital Object Identifier) or a URL to the repository. If the code is associated with a published paper, citing that paper according to its recommended citation style would also be appropriate. For precise citation instructions, it's best to refer to the code's documentation or the publication that introduces or describes the code.\n",
      "**********************************\n",
      "\n",
      "* Which materials has the SRGNN been trained on?\n",
      "\n",
      "The provided context does not specify the materials on which the Sub-Resolution Graph Neural Network (SRGNN) has been trained. Typically, SRGNNs, like other graph neural networks, could be trained on a wide range of materials, including but not limited to, transition metal dichalcogenides (TMDCs), 2D materials, crystals with or without defects, or any atomistic structures depending on the objectives of the research and the availability of data. The choice of materials for training would be guided by the research questions the SRGNN is intended to address, such as predicting material properties, identifying novel materials, or understanding material behaviors at the atomic or molecular level.\n",
      "**********************************\n",
      "\n",
      "* Which materials can the SRGNN be trained on?\n",
      "\n",
      "The Sub-Resolution Graph Neural Network (SRGNN) can potentially be trained on a wide variety of materials, depending on the dataset available and the research objectives. This includes, but is not limited to, 2D materials like graphene, transition metal dichalcogenides (TMDCs), hexagonal boron nitride (hBN), and other layered materials; 3D materials such as metals, alloys, and semiconductors; and materials with complex structures like perovskites, organic-inorganic hybrids, and polymers. The versatility of SRGNNs allows them to be applied to virtually any material system where the structure-property relationships can be represented as a graph of atoms or molecules and their interactions.\n",
      "**********************************\n",
      "\n",
      "* Which defect types can the SRGNN be trained on?\n",
      "\n",
      "The Sub-Resolution Graph Neural Network (SRGNN) can be trained on various types of defects in materials, depending on the dataset it is trained with. This includes point defects (such as vacancies, interstitials, and substitutional atoms), line defects (like dislocations), planar defects (such as grain boundaries and stacking faults), and complex defect structures (including clusters of point defects or mixed defect types). The ability of SRGNNs to handle these defects depends on the representation of the material's atomic structure in the graph model and the quality and diversity of the training data that includes these defect types.\n",
      "**********************************\n",
      "\n",
      "* How many structures are needed for SRGNN training?\n",
      "\n",
      "The number of structures needed for training a Sub-Resolution Graph Neural Network (SRGNN) effectively depends on several factors, including the complexity of the task, the diversity of the materials and defects being modeled, and the desired accuracy of the model. While there is no fixed number, a larger dataset generally helps the model learn more comprehensive representations of the material space. For complex tasks or diverse material systems, datasets can range from thousands to tens of thousands of structures. However, techniques like data augmentation, transfer learning, and few-shot learning can help improve model performance even with smaller datasets.\n",
      "**********************************\n",
      "\n",
      "* Can SRGNN handle 3D materials?\n",
      "\n",
      "Yes, Sub-Resolution Graph Neural Networks (SRGNNs) can handle 3D materials. SRGNNs, like other graph neural networks, are capable of representing and processing 3D structures by constructing graphs where nodes represent atoms or molecules and edges represent the interactions or bonds between them. This allows SRGNNs to learn from the complex spatial relationships and properties inherent in 3D materials, making them suitable for tasks such as predicting material properties, identifying defects, or simulating the behavior of materials under various conditions.\n",
      "**********************************\n",
      "\n",
      "* How much computational resources does SRGNN require for training?\n",
      "\n",
      "The computational resources required for training a Sub-Resolution Graph Neural Network (SRGNN) depend on several factors, including the size and complexity of the dataset, the architecture of the SRGNN, the length of the training process, and the specific task or tasks the network is being trained to perform. Training GNNs on large datasets or for complex tasks typically requires significant computational power, often necessitating the use of GPUs or even multiple GPUs for parallel processing to reduce training time. The exact requirements can vary widely; smaller models and datasets might be manageable on a single GPU, while larger models and datasets could require high-performance computing clusters or cloud computing resources. Efficient data handling, model optimization, and the use of advanced hardware can help manage these resource demands.\n",
      "**********************************\n",
      "\n",
      "* What is the inference speed of a SRGNN?\n",
      "\n",
      "The inference speed of a Sub-Resolution Graph Neural Network (SRGNN) can vary widely based on several factors, including the complexity of the network architecture, the size of the input graph (number of nodes and edges), the hardware used for inference (CPU vs. GPU), and optimizations applied to the model and the computation. Generally, GNNs can perform inference relatively quickly on individual graphs once the model is trained, especially when using GPUs. However, for very large graphs or complex models, inference time can increase significantly. Without specific details on the SRGNN architecture, input graph size, and computational setup, it's challenging to provide a precise inference speed.\n",
      "**********************************\n",
      "\n",
      "* Which properties can be predicted using SRGNN?\n",
      "\n",
      "Sub-Resolution Graph Neural Networks (SRGNNs) can predict a wide range of properties for materials and molecules, depending on their training data and the task they are designed for. These properties can include:\n",
      "\n",
      "1. **Electronic Properties**: Such as band gap, conductivity, and electronic transport properties.\n",
      "2. **Thermodynamic Properties**: Including formation energy, stability, and phase transitions.\n",
      "3. **Mechanical Properties**: Such as hardness, elasticity, and tensile strength.\n",
      "4. **Optical Properties**: Including refractive index, absorption spectrum, and photoluminescence.\n",
      "5. **Chemical Properties**: Such as reaction rates, catalytic activity, and binding energies.\n",
      "\n",
      "The ability to predict these properties accurately depends on the quality and diversity of the training data, the architecture of the SRGNN, and the specific features and interactions encoded in the graph representation of the materials or molecules.\n",
      "**********************************\n",
      "\n",
      "* What was the quality of SRGNN for each property and material?\n",
      "\n",
      "The provided context does not include specific details about the quality of predictions made by the Sub-Resolution Graph Neural Network (SRGNN) for each property and material. The quality of SRGNN predictions typically depends on factors such as the representation of the material in the graph, the diversity and size of the training dataset, and how well the model architecture captures the underlying physics and chemistry of the materials. Performance metrics like mean absolute error (MAE), root mean squared error (RMSE), and coefficient of determination (R^2) are commonly used to evaluate the quality of predictions for various properties. For detailed performance metrics specific to SRGNN on different materials and properties, one would need to refer to the original research articles or reports presenting these results.\n",
      "**********************************\n",
      "\n",
      "* Can pre-trained SRGNN be used out-of-the-box?\n",
      "\n",
      "Yes, a pre-trained Sub-Resolution Graph Neural Network (SRGNN) can be used out-of-the-box for making predictions on materials or molecular systems similar to those it was trained on. Using a pre-trained model can save significant time and computational resources, as it eliminates the need for retraining from scratch. However, the effectiveness of using a pre-trained SRGNN out-of-the-box depends on how well the distribution of the new data matches the training data. For optimal performance on significantly different materials or properties, fine-tuning the pre-trained model with a dataset representative of the new domain may be necessary.\n",
      "**********************************\n",
      "\n",
      "* How well do SRGNN results correspond to experiment?\n",
      "\n",
      "The provided context does not specify how well the Sub-Resolution Graph Neural Network (SRGNN) results correspond to experimental outcomes. Generally, the correspondence between SRGNN predictions and experimental results depends on several factors, including the accuracy and representativeness of the training data, the model's ability to capture the underlying physics and chemistry of the materials, and the complexity of the material systems and properties being modeled. Graph neural networks have shown promise in accurately predicting various material properties, but the degree of correspondence can vary. Validation against experimental data is crucial for assessing the model's predictive performance and reliability.\n",
      "**********************************\n",
      "\n",
      "* Can I use SRGNN in place of DFT?\n",
      "\n",
      "Using a Sub-Resolution Graph Neural Network (SRGNN) in place of Density Functional Theory (DFT) calculations depends on the specific application and the required accuracy. SRGNNs, trained on data from DFT calculations or experimental measurements, can predict material properties much faster than conducting new DFT calculations, making them attractive for screening large numbers of materials efficiently. However, while SRGNNs can offer predictions with accuracy comparable to DFT for the systems and properties they were trained on, they may not capture all the nuances of new or significantly different materials systems as accurately as DFT. Therefore, SRGNNs can complement DFT by narrowing down the search space for new materials, but they might not entirely replace DFT for final validation or for studying materials with poorly understood or novel properties.\n",
      "**********************************\n",
      "\n",
      "* How can I use SRGNN to find materials for solar panels/transistors/photodetectors/single photon emitters/quantum computers?\n",
      "\n",
      "To use a Sub-Resolution Graph Neural Network (SRGNN) for finding materials suitable for applications like solar panels, transistors, photodetectors, single photon emitters, or quantum computers, follow these general steps:\n",
      "\n",
      "1. **Data Collection and Preparation**: Gather a dataset of materials with known performance in your application of interest. This dataset should include both the atomic or molecular structures of the materials and the relevant properties (e.g., bandgap for solar panels, electron mobility for transistors).\n",
      "\n",
      "2. **Feature Representation**: Represent each material in a format suitable for the SRGNN, typically as a graph where nodes represent atoms and edges represent bonds or interactions. Include features that are relevant to the application, such as electronic, optical, and mechanical properties.\n",
      "\n",
      "3. **Model Training**: Train the SRGNN on the prepared dataset. The training process involves adjusting the model parameters to minimize the difference between the predicted and actual properties of the materials in the training set.\n",
      "\n",
      "4. **Prediction and Screening**: Use the trained SRGNN to predict the properties of new or untested materials. Screen these materials based on the predicted properties to identify candidates with the desired characteristics for your application.\n",
      "\n",
      "5. **Validation**: Validate the predictions of the SRGNN with experimental data or high-fidelity simulations (like DFT calculations) for the top candidate materials.\n",
      "\n",
      "6. **Iteration**: Optionally, refine the model by incorporating the new data from validation and retraining. This iterative process can help improve the accuracy of the SRGNN and discover new materials.\n",
      "\n",
      "This approach leverages the speed of SRGNNs for high-throughput screening of materials, significantly reducing the time and computational resources required to identify promising candidates for specific applications.\n",
      "**********************************\n",
      "\n",
      "* Is SRGNN patented?\n",
      "\n",
      "The provided context does not specify whether the Sub-Resolution Graph Neural Network (SRGNN) is patented. Patenting a specific neural network architecture, like an SRGNN, depends on the novelty, utility, and non-obviousness of the invention, as well as the jurisdiction's intellectual property laws. To determine if an SRGNN or a similar technology is patented, one would need to search patent databases or consult with a patent attorney or an intellectual property expert.\n",
      "**********************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l_answer, l_question = [], []\n",
    "\n",
    "for k,v in qa_dict.items():\n",
    "    print(k)\n",
    "    print()\n",
    "    print(v)\n",
    "    print(\"**********************************\")\n",
    "    print()\n",
    "    l_answer.append(v)\n",
    "    l_question.append(k)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e8da5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"9docs&chatHistory&wiki_gpt4\"\n",
    "with open(f'data/data_rag/qa_dict_{name}.json', 'w') as fp:\n",
    "    json.dump(qa_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f9a58e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: * Which materials are in the dataset?\n",
      "AI: The dataset includes materials with and without defects, specifically focusing on TMDCs (transition metal dichalcogenides) and six represented 2D materials. It is based on high throughput DFT (Density Functional Theory) calculations.\n",
      "\n",
      "Human: * How many structures are there in the dataset?\n",
      "AI: The dataset contains a total of 14,866 configurations, comprising 11,866 defect configurations in TMDCs and 3,000 configurations in six represented 2D materials.\n",
      "\n",
      "Human: * How to obtain the dataset?\n",
      "AI: I don't have the specific details on how to obtain the dataset from the provided context. Typically, datasets like these might be accessible through academic publications, associated data repositories, or directly contacting the authors of the studies mentioned.\n",
      "\n",
      "Human: * What is the dataset license?\n",
      "AI: The provided context does not specify the license under which the dataset is distributed. Dataset licenses can vary, often aiming to define how the data can be used, shared, and modified.\n",
      "\n",
      "Human: * What is the data format?\n",
      "AI: The data is provided in two formats: processed data containing only the variables used for machine learning (ML) model evaluation, and the full raw VASP (Vienna Ab initio Simulation Package) output.\n",
      "\n",
      "Human: * How to read the dataset?\n",
      "AI: To read the dataset, the raw VASP output is first converted into CSV or CIF formats, then into a platform-specific pickle storage for efficient access. This process involves extracting computed energy and HOMO-LUMO gap values, saving unrelaxed structures uniformly, and preprocessing target values like formation energy per site.\n",
      "\n",
      "Human: * How to browse the dataset?\n",
      "AI: The provided context does not include specific instructions on browsing the dataset. Typically, browsing a dataset involves accessing its files through a data management tool or software that supports the dataset's format (CSV, CIF, pickle), which might be facilitated by scripts or commands provided by the dataset creators or using standard data analysis tools like Python's pandas library for CSV files or PyCIFRW for CIF files.\n",
      "\n",
      "Human: * Can I work with the dataset without Python?\n",
      "AI: Yes, you can work with the dataset without Python if the data is in formats such as CSV or CIF, which can be opened with various software tools not requiring Python. For example, CSV files can be viewed and edited in spreadsheet applications like Microsoft Excel or Google Sheets, and CIF files can be handled by specialized crystallography software. However, for advanced analyses or transformations, especially those involving the matminer features or machine learning models, Python or similar programming environments might be necessary.\n",
      "\n",
      "Human: * How to obtain the raw VASP files?\n",
      "AI: To obtain the raw VASP files, follow these steps:\n",
      "\n",
      "1. Clone the repository where the dataset is hosted.\n",
      "2. Ensure that DVC with S3 support is installed on your system by running `pip install dvc[s3]`.\n",
      "3. Use the command `dvc pull -R datasets/raw_vasp/high_density_defects datasets/raw_vasp/dichalcogenides8x8_vasp_nus_202110` to download the VASP output files.\n",
      "\n",
      "This process will download the necessary files from the dataset, which include the raw VASP output.\n",
      "\n",
      "Human: * What were the settings used for the DFT computations?\n",
      "AI: The DFT computations were performed using the Vienna Ab initio Simulation Package (VASP) with the projector augmented-wave (PAW) method. The exchange-correlation functional was treated within the generalized gradient approximation (GGA) using the Perdew-Burke-Ernzerhof (PBE) functional. The energy cutoff for the plane-wave basis set was set to 520 eV. A Monkhorst-Pack k-point mesh with a density of approximately 1000 k-points per reciprocal atom was used for Brillouin zone integration. The convergence criteria for the electronic self-consistent loop was set to 10^-6 eV, and the force convergence criterion for ionic relaxations was set to 0.01 eV/Å.\n",
      "\n",
      "Human: * How well the DFT calculations correspond to experiment?\n",
      "AI: The provided context does not specifically address the accuracy of the DFT calculations in comparison to experimental results. Generally, the accuracy of DFT calculations in predicting material properties can vary depending on the system under study and the specific DFT method and parameters used. While DFT is widely used for its balance of computational efficiency and predictive capability, discrepancies between DFT predictions and experimental outcomes can occur, especially for complex material behaviors or when subtle electronic effects are important.\n",
      "\n",
      "Human: * How to cite the dataset?\n",
      "AI: I don't have the specific citation information for the dataset from the provided context. Typically, to cite a dataset, you would include the title of the dataset, the author(s), the year of publication, the version (if applicable), and a persistent identifier such as a DOI (Digital Object Identifier). If the dataset is associated with a specific publication, citing that publication according to its recommended citation style would also be appropriate. For precise citation instructions, it's best to refer to the dataset's documentation or the publication that introduces or describes the dataset.\n",
      "\n",
      "Human: * What was the procedure for SRGNN quality evaluation?\n",
      "AI: The provided context does not detail the specific procedure for evaluating the quality of the SRGNN (Sub-Resolution Graph Neural Network) model. Quality evaluation of machine learning models, including graph neural networks like SRGNN, typically involves comparing the model's predictions against known outcomes in a test dataset. Metrics such as accuracy, precision, recall, F1 score, mean absolute error (MAE), and mean squared error (MSE) are commonly used for evaluation. The procedure might also include cross-validation to assess the model's generalizability and robustness across different subsets of the data.\n",
      "\n",
      "Human: * How is SRGNN different from the baselines?\n",
      "AI: I don't have specific details on how SRGNN (Sub-Resolution Graph Neural Network) differs from baseline models from the provided context. Generally, SRGNNs might be designed to address specific challenges or exploit particular characteristics of the data that are not adequately handled by baseline models. Differences could include the architecture of the network, the way data is processed and represented, the learning algorithm, or the specific task the model is designed for. Baseline models often represent standard approaches in the field, and an SRGNN would be expected to offer improvements in performance, efficiency, or applicability to complex or nuanced problems.\n",
      "\n",
      "Human: * What are the limitations of SRGNN?\n",
      "AI: The provided context does not specify the limitations of the Sub-Resolution Graph Neural Network (SRGNN). Generally, limitations of GNNs, including SRGNNs, might involve challenges in scaling to very large graphs, difficulty in capturing long-range dependencies within the graph, or limitations in the model's expressiveness due to the inherent constraints of the graph neural network architecture. Additionally, GNNs can struggle with graphs that have highly irregular structures or where the graph topology changes dynamically.\n",
      "\n",
      "Human: * What is the core idea of SRGNN?\n",
      "AI: I don't have specific details on the core idea of the Sub-Resolution Graph Neural Network (SRGNN) from the provided context. Generally, the core idea of a Graph Neural Network (GNN) involves leveraging the graph structure of data, where data points (nodes) and their relationships (edges) are explicitly modeled, allowing the network to learn representations not just based on individual data points but also based on their connections. An SRGNN might extend this concept to focus on capturing sub-resolution features or patterns within the graph that are not easily discernible at a higher level, potentially improving the model's ability to understand complex dependencies or structures within the data.\n",
      "\n",
      "Human: * How to run the code?\n",
      "AI: To run the code based on the provided context, follow these general steps:\n",
      "\n",
      "1. **Set up the environment**:\n",
      "   - Refer to `ENVIRONMENT.md` for instructions on setting up the necessary environment. This may involve installing specific software, libraries, or dependencies.\n",
      "\n",
      "2. **Install DVC with S3 support**:\n",
      "   - Ensure you have DVC installed with support for S3 storage by running `pip install dvc[s3]`. This is necessary for data version control and accessing the dataset stored in S3.\n",
      "\n",
      "3. **Clone the repository**:\n",
      "   - Clone the repository where the code and dataset are hosted to your local machine.\n",
      "\n",
      "4. **Download the dataset**:\n",
      "   - Use DVC commands to pull the dataset from the repository. If the dataset is hosted on an external platform like the Constructor Research Platform, you may need to download it directly from there.\n",
      "\n",
      "5. **Run the notebook for model inference**:\n",
      "   - Open the provided notebook that demonstrates how to use the pre-trained models for predictions. This notebook will likely guide you through loading the dataset, making predictions, and possibly evaluating the model's performance.\n",
      "\n",
      "Remember, these steps are based on common practices and the specific instructions provided in the context. Adjustments might be needed depending on the exact setup of the repository and the environment.\n",
      "\n",
      "Human: * Which frameworks were used for SRGNN implementation?\n",
      "AI: The provided context does not specify the frameworks used for the implementation of the Sub-Resolution Graph Neural Network (SRGNN). However, popular frameworks for implementing graph neural networks include PyTorch Geometric (PyG) for PyTorch users, TensorFlow GNN for TensorFlow users, jraph for Google JAX users, and GraphNeuralNetworks.jl or GeometricFlux.jl for those working with Julia. These frameworks offer comprehensive tools and libraries specifically designed for developing and training GNNs, including SRGNNs, if applicable.\n",
      "\n",
      "Human: * Can SRGNN be developed on a CPU, not a GPU?\n",
      "AI: Yes, SRGNN (Sub-Resolution Graph Neural Network) can be developed and run on a CPU. While GPUs offer faster computation for many machine learning tasks, including training graph neural networks due to their parallel processing capabilities, it is entirely possible to develop and train GNNs on CPUs. However, training on a CPU may be significantly slower, especially for large datasets or complex network architectures, and might limit the scale of experiments or the speed of iterative development.\n",
      "\n",
      "Human: * What is the code license?\n",
      "AI: The provided context does not specify the license under which the code is distributed. Code licenses define how software can be used, modified, and distributed. Common open-source licenses include the MIT License, GNU General Public License (GPL), Apache License 2.0, and BSD licenses. For specific code license details, it's important to check the repository's documentation or contact the authors directly.\n",
      "\n",
      "Human: * How to cite the code?\n",
      "AI: I don't have specific citation information for the code from the provided context. Typically, to cite code, you would include the author(s), title of the software or code repository, the year of the latest release, the version (if applicable), and a persistent identifier such as a DOI (Digital Object Identifier) or a URL to the repository. If the code is associated with a published paper, citing that paper according to its recommended citation style would also be appropriate. For precise citation instructions, it's best to refer to the code's documentation or the publication that introduces or describes the code.\n",
      "\n",
      "Human: * Which materials has the SRGNN been trained on?\n",
      "AI: The provided context does not specify the materials on which the Sub-Resolution Graph Neural Network (SRGNN) has been trained. Typically, SRGNNs, like other graph neural networks, could be trained on a wide range of materials, including but not limited to, transition metal dichalcogenides (TMDCs), 2D materials, crystals with or without defects, or any atomistic structures depending on the objectives of the research and the availability of data. The choice of materials for training would be guided by the research questions the SRGNN is intended to address, such as predicting material properties, identifying novel materials, or understanding material behaviors at the atomic or molecular level.\n",
      "\n",
      "Human: * Which materials can the SRGNN be trained on?\n",
      "AI: The Sub-Resolution Graph Neural Network (SRGNN) can potentially be trained on a wide variety of materials, depending on the dataset available and the research objectives. This includes, but is not limited to, 2D materials like graphene, transition metal dichalcogenides (TMDCs), hexagonal boron nitride (hBN), and other layered materials; 3D materials such as metals, alloys, and semiconductors; and materials with complex structures like perovskites, organic-inorganic hybrids, and polymers. The versatility of SRGNNs allows them to be applied to virtually any material system where the structure-property relationships can be represented as a graph of atoms or molecules and their interactions.\n",
      "\n",
      "Human: * Which defect types can the SRGNN be trained on?\n",
      "AI: The Sub-Resolution Graph Neural Network (SRGNN) can be trained on various types of defects in materials, depending on the dataset it is trained with. This includes point defects (such as vacancies, interstitials, and substitutional atoms), line defects (like dislocations), planar defects (such as grain boundaries and stacking faults), and complex defect structures (including clusters of point defects or mixed defect types). The ability of SRGNNs to handle these defects depends on the representation of the material's atomic structure in the graph model and the quality and diversity of the training data that includes these defect types.\n",
      "\n",
      "Human: * How many structures are needed for SRGNN training?\n",
      "AI: The number of structures needed for training a Sub-Resolution Graph Neural Network (SRGNN) effectively depends on several factors, including the complexity of the task, the diversity of the materials and defects being modeled, and the desired accuracy of the model. While there is no fixed number, a larger dataset generally helps the model learn more comprehensive representations of the material space. For complex tasks or diverse material systems, datasets can range from thousands to tens of thousands of structures. However, techniques like data augmentation, transfer learning, and few-shot learning can help improve model performance even with smaller datasets.\n",
      "\n",
      "Human: * Can SRGNN handle 3D materials?\n",
      "AI: Yes, Sub-Resolution Graph Neural Networks (SRGNNs) can handle 3D materials. SRGNNs, like other graph neural networks, are capable of representing and processing 3D structures by constructing graphs where nodes represent atoms or molecules and edges represent the interactions or bonds between them. This allows SRGNNs to learn from the complex spatial relationships and properties inherent in 3D materials, making them suitable for tasks such as predicting material properties, identifying defects, or simulating the behavior of materials under various conditions.\n",
      "\n",
      "Human: * How much computational resources does SRGNN require for training?\n",
      "AI: The computational resources required for training a Sub-Resolution Graph Neural Network (SRGNN) depend on several factors, including the size and complexity of the dataset, the architecture of the SRGNN, the length of the training process, and the specific task or tasks the network is being trained to perform. Training GNNs on large datasets or for complex tasks typically requires significant computational power, often necessitating the use of GPUs or even multiple GPUs for parallel processing to reduce training time. The exact requirements can vary widely; smaller models and datasets might be manageable on a single GPU, while larger models and datasets could require high-performance computing clusters or cloud computing resources. Efficient data handling, model optimization, and the use of advanced hardware can help manage these resource demands.\n",
      "\n",
      "Human: * What is the inference speed of a SRGNN?\n",
      "AI: The inference speed of a Sub-Resolution Graph Neural Network (SRGNN) can vary widely based on several factors, including the complexity of the network architecture, the size of the input graph (number of nodes and edges), the hardware used for inference (CPU vs. GPU), and optimizations applied to the model and the computation. Generally, GNNs can perform inference relatively quickly on individual graphs once the model is trained, especially when using GPUs. However, for very large graphs or complex models, inference time can increase significantly. Without specific details on the SRGNN architecture, input graph size, and computational setup, it's challenging to provide a precise inference speed.\n",
      "\n",
      "Human: * Which properties can be predicted using SRGNN?\n",
      "AI: Sub-Resolution Graph Neural Networks (SRGNNs) can predict a wide range of properties for materials and molecules, depending on their training data and the task they are designed for. These properties can include:\n",
      "\n",
      "1. **Electronic Properties**: Such as band gap, conductivity, and electronic transport properties.\n",
      "2. **Thermodynamic Properties**: Including formation energy, stability, and phase transitions.\n",
      "3. **Mechanical Properties**: Such as hardness, elasticity, and tensile strength.\n",
      "4. **Optical Properties**: Including refractive index, absorption spectrum, and photoluminescence.\n",
      "5. **Chemical Properties**: Such as reaction rates, catalytic activity, and binding energies.\n",
      "\n",
      "The ability to predict these properties accurately depends on the quality and diversity of the training data, the architecture of the SRGNN, and the specific features and interactions encoded in the graph representation of the materials or molecules.\n",
      "\n",
      "Human: * What was the quality of SRGNN for each property and material?\n",
      "AI: The provided context does not include specific details about the quality of predictions made by the Sub-Resolution Graph Neural Network (SRGNN) for each property and material. The quality of SRGNN predictions typically depends on factors such as the representation of the material in the graph, the diversity and size of the training dataset, and how well the model architecture captures the underlying physics and chemistry of the materials. Performance metrics like mean absolute error (MAE), root mean squared error (RMSE), and coefficient of determination (R^2) are commonly used to evaluate the quality of predictions for various properties. For detailed performance metrics specific to SRGNN on different materials and properties, one would need to refer to the original research articles or reports presenting these results.\n",
      "\n",
      "Human: * Can pre-trained SRGNN be used out-of-the-box?\n",
      "AI: Yes, a pre-trained Sub-Resolution Graph Neural Network (SRGNN) can be used out-of-the-box for making predictions on materials or molecular systems similar to those it was trained on. Using a pre-trained model can save significant time and computational resources, as it eliminates the need for retraining from scratch. However, the effectiveness of using a pre-trained SRGNN out-of-the-box depends on how well the distribution of the new data matches the training data. For optimal performance on significantly different materials or properties, fine-tuning the pre-trained model with a dataset representative of the new domain may be necessary.\n",
      "\n",
      "Human: * How well do SRGNN results correspond to experiment?\n",
      "AI: The provided context does not specify how well the Sub-Resolution Graph Neural Network (SRGNN) results correspond to experimental outcomes. Generally, the correspondence between SRGNN predictions and experimental results depends on several factors, including the accuracy and representativeness of the training data, the model's ability to capture the underlying physics and chemistry of the materials, and the complexity of the material systems and properties being modeled. Graph neural networks have shown promise in accurately predicting various material properties, but the degree of correspondence can vary. Validation against experimental data is crucial for assessing the model's predictive performance and reliability.\n",
      "\n",
      "Human: * Can I use SRGNN in place of DFT?\n",
      "AI: Using a Sub-Resolution Graph Neural Network (SRGNN) in place of Density Functional Theory (DFT) calculations depends on the specific application and the required accuracy. SRGNNs, trained on data from DFT calculations or experimental measurements, can predict material properties much faster than conducting new DFT calculations, making them attractive for screening large numbers of materials efficiently. However, while SRGNNs can offer predictions with accuracy comparable to DFT for the systems and properties they were trained on, they may not capture all the nuances of new or significantly different materials systems as accurately as DFT. Therefore, SRGNNs can complement DFT by narrowing down the search space for new materials, but they might not entirely replace DFT for final validation or for studying materials with poorly understood or novel properties.\n",
      "\n",
      "Human: * How can I use SRGNN to find materials for solar panels/transistors/photodetectors/single photon emitters/quantum computers?\n",
      "AI: To use a Sub-Resolution Graph Neural Network (SRGNN) for finding materials suitable for applications like solar panels, transistors, photodetectors, single photon emitters, or quantum computers, follow these general steps:\n",
      "\n",
      "1. **Data Collection and Preparation**: Gather a dataset of materials with known performance in your application of interest. This dataset should include both the atomic or molecular structures of the materials and the relevant properties (e.g., bandgap for solar panels, electron mobility for transistors).\n",
      "\n",
      "2. **Feature Representation**: Represent each material in a format suitable for the SRGNN, typically as a graph where nodes represent atoms and edges represent bonds or interactions. Include features that are relevant to the application, such as electronic, optical, and mechanical properties.\n",
      "\n",
      "3. **Model Training**: Train the SRGNN on the prepared dataset. The training process involves adjusting the model parameters to minimize the difference between the predicted and actual properties of the materials in the training set.\n",
      "\n",
      "4. **Prediction and Screening**: Use the trained SRGNN to predict the properties of new or untested materials. Screen these materials based on the predicted properties to identify candidates with the desired characteristics for your application.\n",
      "\n",
      "5. **Validation**: Validate the predictions of the SRGNN with experimental data or high-fidelity simulations (like DFT calculations) for the top candidate materials.\n",
      "\n",
      "6. **Iteration**: Optionally, refine the model by incorporating the new data from validation and retraining. This iterative process can help improve the accuracy of the SRGNN and discover new materials.\n",
      "\n",
      "This approach leverages the speed of SRGNNs for high-throughput screening of materials, significantly reducing the time and computational resources required to identify promising candidates for specific applications.\n",
      "\n",
      "Human: * Is SRGNN patented?\n",
      "AI: The provided context does not specify whether the Sub-Resolution Graph Neural Network (SRGNN) is patented. Patenting a specific neural network architecture, like an SRGNN, depends on the novelty, utility, and non-obviousness of the invention, as well as the jurisdiction's intellectual property laws. To determine if an SRGNN or a similar technology is patented, one would need to search patent databases or consult with a patent attorney or an intellectual property expert.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in conversational_rag_chain.get_session_history(\"abc123\").messages:\n",
    "    \n",
    "    if m.type == 'human':\n",
    "        print('Human: ' + m.content)\n",
    "    elif  m.type == 'ai':\n",
    "        print('AI: ' + m.content)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "86e3755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "l_answer, l_question = [], []\n",
    "\n",
    "for m in conversational_rag_chain.get_session_history(\"abc123\").messages:\n",
    "    \n",
    "    if m.type == 'human':\n",
    "        l_question.append(m.content)\n",
    "    elif  m.type == 'ai':\n",
    "        l_answer.append(m.content)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['question'] = l_question\n",
    "#df['Content'] = doc_url[0].metadata['description']\n",
    "df['answer'] = l_answer\n",
    "df['number of documets'] = len(documents)\n",
    "#for i in range(len(documents)):\n",
    "    #df[f'Content_{i}'] = documents[i].metadata['description']\n",
    "    #df[f'Titles_{i}'] = documents[i].metadata['title']\n",
    "    #df[f'Urls_{i}'] = documents[i].metadata['source']\n",
    "\n",
    "df.to_csv(f\"data/data_rag/{name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "390374f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, there is a significant relationship between defects and the HOMO-LUMO (Highest Occupied Molecular Orbital - Lowest Unoccupied Molecular Orbital) gap in materials. Defects in a material can introduce localized states within the band gap, which can alter the energy levels of the HOMO and LUMO, thereby affecting the size of the HOMO-LUMO gap. This alteration can influence the electronic, optical, and chemical properties of the material. For instance, the presence of defects can reduce the band gap, making a material more conductive or altering its absorption properties, which is particularly relevant in applications like photovoltaics and semiconductors. The specific impact depends on the nature of the defects and their interaction with the material's electronic structure.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = conversational_rag_chain.invoke(\n",
    "              {\"input\": \"Is there any relaion between defects and HUM0-LUMO gap?\"},\n",
    "               config={\"configurable\": {\"session_id\": \"abc123\"}\n",
    "              },  # constructs a key \"abc123\" in `store`.\n",
    "             )[\"answer\"]\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5317f26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The effect of defects on the HOMO-LUMO gap largely depends on the type and concentration of the defects within the material. Generally, deep-level defects, such as vacancy defects or substitutional defects, have a more pronounced effect on the HOMO-LUMO gap compared to shallow-level defects. \\n\\n- **Vacancy defects**, where atoms are missing from the lattice, can introduce deep states within the band gap that significantly alter the electronic structure and, consequently, the HOMO-LUMO gap.\\n- **Substitutional defects**, where one type of atom is replaced by another, can also introduce localized states that affect the band gap depending on the electronic nature of the substituting atom.\\n\\nThe impact of these defects on the HOMO-LUMO gap is critical because it can change the material's optical and electronic properties, influencing its suitability for applications like semiconductors, photovoltaics, and sensors. The extent of the effect also depends on the defect's energy level relative to the HOMO and LUMO levels and the defect concentration within the material.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = conversational_rag_chain.invoke(\n",
    "              {\"input\": \"Which defects have more effect on HUM0-LUMO gap?\"},\n",
    "               config={\"configurable\": {\"session_id\": \"abc123\"}\n",
    "              },  # constructs a key \"abc123\" in `store`.\n",
    "             )[\"answer\"]\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d2867e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atoms that are effective in increasing the HOMO-LUMO gap as defects typically have characteristics that significantly alter the electronic structure of the host material. These include:\n",
      "\n",
      "1. **Atoms with a High Electronegativity**: Atoms that are more electronegative than the host material atoms can pull the electron density towards themselves, potentially increasing the energy of the lowest unoccupied molecular orbital (LUMO) and thus widening the HOMO-LUMO gap.\n",
      "\n",
      "2. **Atoms with a Different Number of Valence Electrons**: Atoms that introduce a different number of valence electrons compared to the atoms they replace in the host material can create localized energy states within the band structure. If these states are closer to the conduction band, they can effectively increase the HOMO-LUMO gap.\n",
      "\n",
      "3. **Atoms that Induce Lattice Strain**: Atoms significantly larger or smaller than the host atoms can induce lattice strain, which can modify the band structure and potentially increase the band gap. This effect is due to the altered atomic spacing and the resulting changes in the electronic band structure.\n",
      "\n",
      "The specific impact of defect atoms on the HOMO-LUMO gap also depends on the host material's crystal and electronic structure, making it a complex interaction that often requires detailed computational or experimental analysis to predict accurately.\n"
     ]
    }
   ],
   "source": [
    "answer = conversational_rag_chain.invoke(\n",
    "              {\"input\": \"Which atoms as defects  are more effective to increase HUM0-LUMO gap?\"},\n",
    "               config={\"configurable\": {\"session_id\": \"abc123\"}\n",
    "              },  # constructs a key \"abc123\" in `store`.\n",
    "             )[\"answer\"]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2954a114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materials with a crystal structure that allows for significant modification of their electronic properties through defect engineering are particularly perspective for increasing the HOMO-LUMO gap. These include:\n",
      "\n",
      "1. **Semiconductors with Wide Band Gaps**: Materials like zinc oxide (ZnO) and titanium dioxide (TiO2) have wide band gaps that can be further manipulated through doping or defect introduction, making them suitable for applications requiring high-energy photon absorption or emission.\n",
      "\n",
      "2. **Two-Dimensional (2D) Materials**: Graphene, transition metal dichalcogenides (TMDCs) like MoS2 and WSe2, and hexagonal boron nitride (h-BN) are highly sensitive to defects due to their two-dimensional nature. Defects or dopants in these materials can significantly alter their electronic and optical properties, including the HOMO-LUMO gap.\n",
      "\n",
      "3. **Perovskites**: Hybrid organic-inorganic perovskites have tunable band gaps and are promising for photovoltaic applications. Defect engineering in these materials can lead to improved light absorption and increased efficiency in solar cells.\n",
      "\n",
      "4. **Diamond and Silicon Carbide (SiC)**: Both have wide band gaps and high thermal conductivity, making them ideal for high-power and high-frequency electronic devices. Introducing defects or dopants can further increase their band gap, enhancing their performance in electronic applications.\n",
      "\n",
      "These materials are particularly attractive for applications requiring materials with specific electronic and optical properties, such as photovoltaics, light-emitting diodes (LEDs), and high-power electronics. The ability to increase the HOMO-LUMO gap through defect engineering can lead to materials with improved efficiency and new functionalities.\n"
     ]
    }
   ],
   "source": [
    "answer = conversational_rag_chain.invoke(\n",
    "              {\"input\": \"Which material's crystal  are more perspective to get a materials with increasing HUM0-LUMO gap?\"},\n",
    "               config={\"configurable\": {\"session_id\": \"abc123\"}\n",
    "              },  # constructs a key \"abc123\" in `store`.\n",
    "             )[\"answer\"]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fc8028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
